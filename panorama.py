# -*- coding: utf-8 -*-
"""panorama.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BLUpIqiyq93XgglCc3WMV9Tn7S7UaL6w
"""

from google.colab import drive
drive.mount('/content/drive')
!ls /content/drive/MyDrive/Colab\ Notebooks/data/

import numpy as np
import torch

import matplotlib.pyplot as plt
import scipy.ndimage as scimage
from skimage.transform import warp
import torch.nn as nn
from skimage import io

!pip install opencv-contrib-python==4.4.0.44
import cv2
print (cv2 .__version__)


np.set_printoptions(precision=2, suppress=True)
torch.set_printoptions(precision=2, sci_mode=False)

"""# Code: Detect and match SIFT keypoints between two images"""

def detect_and_match_keypoints (image_1, image_2) :
    # input are just two images
    # returns SIFT key points and descriptors for each image along with sorted match list (plus pairs of point matching coordinates) 

    print("Input image size:", image_1.shape)

    # SIFT with default parameters
    sift = cv2.SIFT_create(nOctaveLayers = 3, contrastThreshold = 0.04, edgeThreshold = 10, sigma = 0.8)

    keypoints_1, descriptors_1 = sift.detectAndCompute(image_1, None)
    keypoints_2, descriptors_2 = sift.detectAndCompute(image_2, None)

    # FEATURE MATCHING
    bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)

    matches = bf.match(descriptors_1, descriptors_2)
    matches = sorted(matches, key = lambda x:x.distance)
    X_1 = []
    X_2 = []
    for i in range(len(matches)) :
        X_1.append([keypoints_1[matches[i].queryIdx].pt[0], keypoints_1[matches[i].queryIdx].pt[1]])
        X_2.append([keypoints_2[matches[i].trainIdx].pt[0], keypoints_2[matches[i].trainIdx].pt[1]])
    X_1 = np.array(X_1)
    X_2 = np.array(X_2)

    return(X_1, X_2, keypoints_1, keypoints_2, matches)

def fit_affine_remove_outliers (Points_1, Points_2, acceptable_error = 2) :
    # input: two 2D points sets, each of size N by 2
    # output: residual of fit and the best fitting affine transformation
    # acceptable_error - amount of average pixel error that is acceptable

    # Rearrange the points in 3 by N arrays of homogeneous representation of the points
    X = np.row_stack((Points_1.transpose(1,0), np.ones((1, Points_1.shape[0]))))
    X_dash = np.row_stack((Points_2.transpose(1,0), np.ones((1, Points_2.shape[0]))))
    
    weights = np.eye(X.shape[1])
    average_residual_error = np.sqrt(np.sum(np.power(X - X_dash, 2)/X.shape[1]))
    while average_residual_error > acceptable_error :  # while loop removes the worst outlier at each step
        # Compute the Hessian from the point coordinate moments
        print('in for loop')
        M = X @ weights @ X.transpose(1,0)
        A1 = np.column_stack((M, np.zeros((3,3))))
        A2 = np.column_stack((np.zeros((3,3)), M))
        A = np.row_stack((A1, A2))
        #print('A =\n', A)

        # vector b
        b_dash = X @ weights @(X_dash - X).transpose(1,0)
        b = np.row_stack((b_dash[:,0][:,None], b_dash[:,1][:,None]))
        #print('b =\n', b)

        p = qr_solve (A, b) 

        p = p.squeeze()
        # the parameter vector is [a_00, a_01, t_x, a_10, a_11, t_y]
        # rearrange it back into homogeneous matrix representation
        T_affine = np.row_stack((p.reshape(2, 3), [0, 0, 0])) + np.eye(3)
        
        X_t = T_affine @ X
        error =  (X_dash - X_t) @ weights
        residual_error = np.sum(np.power(error, 2), axis=0)
        average_residual_error = np.sqrt(np.sum(residual_error)/np.sum(weights))
        selected_matches = np.diag(weights).copy()  # diag return the variable by reference so have to copy
        print('residual error = {}, matches removed # {}'.format(average_residual_error, np.where(selected_matches==0)[0]))

        # Identify the largest outlier and remove it by setting weight to 0
        max_index = np.argmax(residual_error)
        weights[max_index, max_index] = 0

    return(average_residual_error, T_affine, selected_matches)

def qr_solve (A, b) :
    Q, R = np.linalg.qr(A, 'reduced')
    b_dash = Q.transpose(1,0) @ b
    Np = b_dash.shape[0]
    del_p = np.zeros((Np, 1))
    for i in range(Np-1, -1, -1): # work from the last row of R
        sum_r_p = [0]
        for j in range(i+1, Np, 1) :
            sum_r_p += R[i, j]*del_p[j]
        del_p[i] = (b_dash[i]- sum_r_p)/R[i,i]

    return(del_p)

"""# Code: Affine fitting (great candidate for an initial estimate)"""

def J_perspective (H, X) :
    # X is 3 by N array of points
    # H is a 3 by 3 matrix
    # output is the Jacobian of each point -- sized N by 2 by 8
    X_hat = (H + np.eye(3))@ X # transformed points
    X_hat = X_hat/X_hat[2,:]

    D = H[2,0]*X[0,:] + H[2,1]*X[1,:] + 1

    N = X.shape[1]
    J = np.zeros((N, 2, 8))
    J[:, 0,0] = X[0,:]/D 
    J[:, 0,1] = X[1,:]/D
    J[:, 0,2] = np.ones((N))/D
    J[:, 1,3] = J[:, 0,0] 
    J[:, 1,4] = J[:, 0,1]
    J[:, 1,5] = np.ones((N))/D
    J[:, 0,6] = -(X[0,:]*X_hat[0,:])/D
    J[:, 0,7] = -(X[1,:]*X_hat[0,:])/D
    J[:, 1,6] = -(X[0,:]*X_hat[1,:])/D
    J[:, 1,7] = -(X[1,:]*X_hat[1,:])/D

    return(J)

def initialize_with_affine (Input_points, Output_points, acceptable_error=10) :
    '''Estimate initial parameters by fitting an affine transformation and returns
     the error, affine transformation, along with the points (minus outliers) in 
     homogeneous coordinate form'''

    print('Performing affine fit with outlier detection to be used as initial parameters')
    error, T_affine, matches_selected  = fit_affine_remove_outliers (Input_points, Output_points, acceptable_error) 
    #print('Affine residual =\n', error, '\n Affine transform =\n', T_affine)

    # delete outlier points identified during affine fittinf
    points_deleted = np.where(matches_selected == 0)[0]
    print('Outlier matches deleted: ', points_deleted)
    Input_points  = np.delete(Input_points, points_deleted, 0)
    Output_points  = np.delete(Output_points, points_deleted, 0)

    # create homogeneous representation
    X1 = np.row_stack((Input_points.transpose(1,0), np.ones((1, Input_points.shape[0]))))
    X2 = np.row_stack((Output_points.transpose(1,0), np.ones((1, Output_points.shape[0]))))

    return (T_affine, X1, X2, matches_selected)

def fit_Gauss_Newton (Input_pts, Output_pts, acceptable_error =10) :
    ''' function for non-linear estimation of perspective transformation. It returns the
    final square root mean squared residual and the final transformation 3 by 3 matrix.'''

    p_current, X, X_dash, matches_selected = initialize_with_affine (Input_pts, Output_pts, acceptable_error)

    # starting residual per point
    X_t = p_current @ X  # the third row is all 1 as transform as 0 0 1 in last row so can leave it
    residual = X_dash - X_t
    residual = residual[0:2,:] # remove the third row of zeros
    old_residual = np.sqrt(np.power(residual, 2).sum()/residual.shape[1])

    #----------------Iterative non-linear optimization------------------------
    # at each iteration find the change in parameters del_p that minimizes the overall
    # residual fit error.
    print('starting residual=\n', old_residual, '\n transform =\n', p_current)
    change_in_residual = 1.0
    p_current = p_current - np.eye(3,3) # re-parametrization of the perspective transformation (recall, p=0 is the identity)
    while change_in_residual > 0.1:
        # Compute Jacobian and its transpose
        J = J_perspective(p_current.reshape(3,3), X)  # N by 2 by 8
        J_T = J.transpose(0, 2, 1)
        #print('Jacobian=\n', J)

        # Compute the Hessian and vector b
        A = np.sum((J_T @ J), 0)
        b = np.sum((J_T @ residual[:,None,:].transpose(2,0,1)), 0)
        #print('A=\n', A)
        #print('b=\n', b)
        
        #del_p = qr_solve(A, b)
        del_p = np.linalg.inv(A) @ b
        #print(A.dtype,'\nA=\n', A, '\n invA=\n',  np.linalg.inv(A), '\n b=\n', b.dtype, b, '\n del_p=\n', del_p.dtype, del_p)   

        p_current  = p_current.reshape(9,1) + np.row_stack((del_p, [0]))

        # compute new residuals
        X_t = (p_current.reshape(3,3) + np.eye(3,3)) @ X # compute the points after transformation
        X_t= X_t/X_t[2,:] # normalize the homogenous representation of the points w.r.t the third coordinate
        residual = X_dash - X_t # current displacemen between final (X_dash) and transformed pt (X_t)
        residual = residual[0:2,:] # remove the third row of zeros

        new_residual = np.sqrt(np.power(residual, 2).sum()/residual.shape[1]) # root mean squared error
        change_in_residual = (old_residual - new_residual)/old_residual # change in residual at each iteration 
        old_residual = new_residual # getting ready for next iteration  
        print('new_residual=', new_residual, '\n transform =\n', p_current.reshape(3,3))
        #print('Residual vector=\n', residual)

    return(new_residual, p_current.reshape(3,3)+np.eye(3), matches_selected)

def trim(frame):
  #crop top
  if not np.sum(frame[0]):
      return trim(frame[1:])
  #crop top
  if  not np.sum(frame[-1]):
      return trim(frame[:-2])
  #crop top
  if not np.sum(frame[:,0]):
      return trim(frame[:,1:])
  #crop top
  if not np.sum(frame[:,-1]):
      return trim(frame[:,:-2])
  return frame

def create_mask(img1,img2,version):
  height_img1 = img1.shape[0]
  width_img1 = img1.shape[1]
  width_img2 = img2.shape[1]
  height_panorama = height_img1
  width_panorama = width_img1 +width_img2
  offset = int(smoothing_window_size / 2)
  barrier = img1.shape[1] - int(smoothing_window_size / 2)
  mask = np.zeros((height_panorama, width_panorama))
  if version== 'left_image':
      mask[:, barrier - offset:barrier + offset ] = np.tile(np.linspace(1, 0, 2 * offset ).T, (height_panorama, 1))
      mask[:, :barrier - offset] = 1
  else:
      mask[:, barrier - offset :barrier + offset ] = np.tile(np.linspace(0, 1, 2 * offset ).T, (height_panorama, 1))
      mask[:, barrier + offset:] = 1
  return cv2.merge([mask, mask, mask])



def main():
  image_names=['data/blog_danforth_monica_mural_panorama.jpg','data/blog_monica_mural_brown_white.jpg','data/blog_monica_mural_fish_tree_windows1.jpg']
  images_list=[]     #creating an empty list to store the images to be transformed  
  for image in image_names:
    images_list.append(cv2.imread(image))
  image_1=images_list[0]     #storing first image in image_1
  image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)    #converting first image from BGR to RGB format
  for image_2 in images_list[1:]:   # looping from second image
    image_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB)
    X_1, X_2, keypoints_1, keypoints_2, matches = detect_and_match_keypoints (image_1, image_2)   #finding the matching points from detector and descriptor
    top_matches = 25
    X_1 = X_1[:top_matches,:]
    X_2 = X_2[:top_matches,:]


    #-----------call to non linear fitting function-------------------
    residual, T, selected_matches = fit_Gauss_Newton (X_1, X_2, acceptable_error=2)
    #--------------------------------------------------------------

    T_inv = np.linalg.inv(T)
    print('T =\n{}\n T_inv =\n{}'.format(T, T_inv))

    warped_1_into_2 = warp(image_1, inverse_map=T_inv, output_shape=image_2.shape)
    #warping image into 1. output of the warped image should have a width of image1_width+image2_width
    warped_2_into_1 = warp(image_2, inverse_map=T, output_shape=(image_2.shape[0] ,image_1.shape[1]+image_2.shape[1]))  

    #generating mask for common regions
    mask=warped_2_into_1>0    # getting non-zero regions from the warped image
    mask[:,image_1.shape[1]:]=False  # making non-intersection part with image1 to zero
    mask=~mask
    warped_2_into_1[0:image_1.shape[0],0:image_1.shape[1]]+=(image_1/255)

    warped_2_into_1=np.where(mask,warped_2_into_1,warped_2_into_1*0.5)   #averaging the pixel values of intersection area
    warped_2_into_1=trim(warped_2_into_1)   # removing the extra part from image

    image_1=warped_2_into_1
    image_1=image_1*255
    image_1=image_1.astype(np.uint8)
  plt.imshow(image_1)

if __name__=="__main__":
  main()

!unzip '/content/drive/MyDrive/Colab Notebooks/data.zip'

